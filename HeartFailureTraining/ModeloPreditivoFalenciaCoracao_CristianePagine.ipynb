{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNEacqYPxoUNuW4GPPjXLSe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Montar o Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Importar bibliotecas\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n","\n","# Carregar o dataset\n","file_path = '/content/drive/MyDrive/Colab Notebooks/heart_failure_clinical_records_dataset.csv'\n","\n","data = pd.read_csv(file_path)\n","print(data.head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"o7rwXxwV_V07","executionInfo":{"status":"ok","timestamp":1750249636007,"user_tz":180,"elapsed":1536,"user":{"displayName":"Cristiane Pagine","userId":"14007945378641161929"}},"outputId":"6af2cf46-86b3-41d6-c383-8218c81fd289"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n","0  75.0        0                       582         0                 20   \n","1  55.0        0                      7861         0                 38   \n","2  65.0        0                       146         0                 20   \n","3  50.0        1                       111         0                 20   \n","4  65.0        1                       160         1                 20   \n","\n","   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n","0                    1  265000.00               1.9           130    1   \n","1                    0  263358.03               1.1           136    1   \n","2                    0  162000.00               1.3           129    1   \n","3                    0  210000.00               1.9           137    1   \n","4                    0  327000.00               2.7           116    0   \n","\n","   smoking  time  DEATH_EVENT  \n","0        0     4            1  \n","1        0     6            1  \n","2        1     7            1  \n","3        0     7            1  \n","4        0     8            1  \n"]}]},{"cell_type":"code","source":["# Preparar variáveis preditoras (X) e alvo (y)\n","X = data.drop('DEATH_EVENT', axis=1)\n","y = data['DEATH_EVENT']\n","\n","# Dividir em treino e teste (70% treino, 30% teste), com estratificação\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.3, random_state=42, stratify=y)\n","\n","# Treinar os modelos\n","dt = DecisionTreeClassifier(random_state=42)\n","dt.fit(X_train, y_train)\n","y_pred_dt = dt.predict(X_test)\n","\n","svm = SVC(kernel='linear', random_state=42)\n","svm.fit(X_train, y_train)\n","y_pred_svm = svm.predict(X_test)\n","\n","mlp = MLPClassifier(random_state=42, max_iter=500)\n","mlp.fit(X_train, y_train)\n","y_pred_mlp = mlp.predict(X_test)\n","\n","# Função para calcular métricas\n","def calcular_metricas(y_true, y_pred):\n","    return {\n","        'Acurácia': accuracy_score(y_true, y_pred),\n","        'F1-Score': f1_score(y_true, y_pred),\n","        'Recall': recall_score(y_true, y_pred),\n","        'Precisão': precision_score(y_true, y_pred)\n","    }\n","\n","# Calcular métricas\n","metricas_dt = calcular_metricas(y_test, y_pred_dt)\n","metricas_svm = calcular_metricas(y_test, y_pred_svm)\n","metricas_mlp = calcular_metricas(y_test, y_pred_mlp)\n","\n","# Criar DataFrame para exibir resultados\n","df_metricas = pd.DataFrame([metricas_dt, metricas_svm, metricas_mlp],\n","                           index=['Árvore de Decisão', 'SVM Linear', 'MLP Neural Network'])\n","\n","print(\"Métricas dos Modelos:\")\n","print(df_metricas.round(4))\n","\n","# Imprimir matrizes de confusão\n","print('\\nMatrizes de Confusão:')\n","print('Árvore de Decisão:')\n","print(confusion_matrix(y_test, y_pred_dt))\n","print('\\nSVM Linear:')\n","print(confusion_matrix(y_test, y_pred_svm))\n","print('\\nMLP Neural Network:')\n","print(confusion_matrix(y_test, y_pred_mlp))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FZSuD9rIASKN","executionInfo":{"status":"ok","timestamp":1750249726221,"user_tz":180,"elapsed":47635,"user":{"displayName":"Cristiane Pagine","userId":"14007945378641161929"}},"outputId":"fea3cda4-3927-46ed-d093-e0446da31921"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Métricas dos Modelos:\n","                    Acurácia  F1-Score  Recall  Precisão\n","Árvore de Decisão     0.7889    0.6545  0.6207    0.6923\n","SVM Linear            0.8000    0.6250  0.5172    0.7895\n","MLP Neural Network    0.3333    0.4915  1.0000    0.3258\n","\n","Matrizes de Confusão:\n","Árvore de Decisão:\n","[[53  8]\n"," [11 18]]\n","\n","SVM Linear:\n","[[57  4]\n"," [14 15]]\n","\n","MLP Neural Network:\n","[[ 1 60]\n"," [ 0 29]]\n"]}]},{"cell_type":"markdown","source":["O modelo de Árvore de Decisão apresentou um desempenho equilibrado, com uma acurácia de 78,9% e um F1-Score razoável (0,65). Ele conseguiu identificar cerca de 62% dos casos positivos reais (recall) e manteve uma precisão moderada (69%), o que indica um bom equilíbrio entre identificar corretamente os positivos e evitar falsos positivos. A matriz de confusão mostra que o modelo cometeu poucos erros, tanto em falsos positivos quanto em falsos negativos.\n","\n","O SVM Linear teve uma acurácia ligeiramente maior (80%), porém seu recall foi menor (51,7%), o que significa que deixou passar quase metade dos casos positivos. Por outro lado, sua precisão foi alta (79%), indicando que, quando o modelo previu um caso positivo, geralmente acertou. Isso sugere que o SVM é mais conservador, classificando menos exemplos como positivos para evitar falsos positivos, mas perdendo alguns positivos reais.\n","\n","O modelo MLP Neural Network apresentou o pior desempenho geral, com uma acurácia baixa (33,3%) e baixa precisão (32,6%), apesar de alcançar um recall perfeito (100%). Isso indica que o MLP classificou praticamente todos os exemplos como positivos, o que garantiu identificar todos os positivos reais, porém resultou em muitos falsos positivos, conforme confirmado pela matriz de confusão que mostra 60 falsos positivos e apenas 1 verdadeiro negativo."],"metadata":{"id":"8Bhfg885DYPz"}}]}